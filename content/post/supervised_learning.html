---
title: 'sparklyr: supervised learning'
author: "Samuel Macêdo"
date: '2018-05-28'
categories: ["tutorials"]
tags: ["sparklyr"]
description: "This tutorial will present you how to train, predict and evaluate your models."
--- 



<p>Welcome, friend :)</p>
<p>In this tutorial, I am going to present you how to perform supervised learning in R using the <a href="https://spark.rstudio.com/">sparklyr</a> package. The models that I am going to use are:</p>
<ul>
<li>Linear Regression</li>
<li>Naive Bayes</li>
<li>Decision Tree</li>
<li>Random Forest</li>
<li>Logistic Regression</li>
<li>Multilayer Perceptron</li>
<li>Gradient Boosted Tree</li>
<li>Support Vector Machine</li>
</ul>
<p>If you don’t know how to connect spark in R, don’t worry…check <a href="http://samuelmacedo.netlify.com/2018/05/sparklyr-connecting-spark-in-local-mode/">this</a> out. If you have any question or suggestions, don’t hesitate to contact me on <code>samuelmacedo@recife.ifpe.edu.br</code>.</p>
<p>Let’s get to action…</p>
<div id="loading-data" class="section level1">
<h1>Loading data</h1>
<p>First of all, we need to make a connection between spark and R. After, we are going to add data to connection, transforming a data frame in a spark data frame.</p>
<pre class="r"><code>library(sparklyr)
library(dplyr) # we&#39;ll need this to do some manipulations on data

sc &lt;- spark_connect(master = &quot;local&quot;)

# using iris for binary classification examples
iris_bin_tbl &lt;- sdf_copy_to(sc, iris, name = &quot;iris_bin_tbl&quot;, overwrite = TRUE) %&gt;% 
  filter(Species != &quot;setosa&quot;)

# using iris for multiclass classification examples
iris_tbl &lt;- sdf_copy_to(sc, iris, name = &quot;iris_tbl&quot;, overwrite = TRUE)

# using mtcars for regression examples
mtcars_tbl &lt;- sdf_copy_to(sc, mtcars, name = &quot;mtcars_tbl&quot;, overwrite = TRUE)</code></pre>
</div>
<div id="partitioning-in-training-and-testing" class="section level1">
<h1>Partitioning in training and testing</h1>
<p>You can partition your data as you like: 70/30, 75/25, 80/20…</p>
<pre class="r"><code># for iris_bin_tbl
partitions &lt;- iris_bin_tbl %&gt;%
  sdf_partition(training = 0.7, test = 0.3, seed = 1111)

iris_bin_training &lt;- partitions$training
iris_bin_test &lt;- partitions$test

# for iris_tbl
partitions &lt;- iris_tbl %&gt;%
  sdf_partition(training = 0.7, test = 0.3, seed = 1111)

iris_training &lt;- partitions$training
iris_test &lt;- partitions$test

# for mtcars_tbl
partitions &lt;- mtcars_tbl %&gt;%
  sdf_partition(training = 0.7, test = 0.3, seed = 1111)

mtcars_training &lt;- partitions$training
mtcars_test &lt;- partitions$test</code></pre>
</div>
<div id="training-predicting-and-evaluating-your-models" class="section level1">
<h1>Training, predicting and evaluating your models</h1>
<p>Now that you split your data in training and test, let’s move to the fun part: train your model, make predictions and, of course, evaluate the results. Let’s see a summary of how each of these steps works in sparklyr.</p>
<ul>
<li><p>Model training: Basically, all the models have the same syntax: <code>your_model &lt;- ml_function(training_data, formula)</code>. Some models, like Random Forest, perform more than one type of prediction, in these cases you have to add <code>type</code> parameter. Multiplayer perceptron is a quite different because you have to input layers configuration, but it isn’t difficult at all.</p></li>
<li><p>Make predictions: After training, you need to include the prediction column in your spark data frame. Only you have to do is to use <code>pred &lt;- sdf_predict(test_data, your_model)</code>.</p></li>
<li><p>Evaluating your model: Here, you have to use the evaluator according to your output. You can use one of this in <code>pred</code> data frame: <code>ml_regression_evaluator()</code>, <code>ml_binary_classification_evaluator()</code> or <code>ml_multiclass_classification_evaluator()</code>. Sparklyr doesn’t support a function for confusion matrix yet, if you want to analyse this, you can use <code>dplyr::collect(pred)</code> and use <code>table(groundtruth, prediction)</code>. WARNING: Don’t use <code>collect()</code> when you have a data frame larger than your memory, you’ll lose the connection with spark. I suggest you estimate your confusion matrix with a sample using <code>sdf_sample()</code>. I know…I know that is not the best solution but it is what we have for while :(</p></li>
</ul>
<p>Does it seem complicated? Don’t worry… let’s check it out how easy is to train your models with sparklyr :)</p>
<div id="training-your-model" class="section level2">
<h2>Training your model</h2>
<pre class="r"><code># linear regression
lm_model &lt;- mtcars_training %&gt;%
  ml_linear_regression(mpg ~ .)

# naive bayes
nb_model &lt;- iris_training %&gt;%
  ml_naive_bayes(Species ~ .)

# decision tree
dt_model &lt;- iris_training %&gt;%
  ml_decision_tree(Species ~ .)

# random forest (regression)
rf_model_reg &lt;- mtcars_training %&gt;%
  ml_random_forest(cyl ~ ., type = &quot;regression&quot;)

# random forest (classification)
rf_model_class &lt;- iris_training %&gt;%
  ml_random_forest(Species ~ ., type = &quot;classification&quot;)

# gradient boosted tree (regression)
gbt_model_reg &lt;- mtcars_training %&gt;%
  ml_gradient_boosted_trees(cyl ~ ., type = &quot;regression&quot;)

# gradient boosted tree (binary). Multiclass classification is not implemented unitl now. When it works I&#39;ll update this tutorial
gbt_model_bin &lt;- iris_bin_training %&gt;% 
  ml_gradient_boosted_trees(Species ~ ., type = &quot;classification&quot;)

# logistic regression
lr_model &lt;- iris_bin_training %&gt;%
  ml_logistic_regression(Species ~ .)

# multilayer perceptron
mlp_model &lt;- iris_training %&gt;%
  ml_multilayer_perceptron(Species ~ ., layers = c(4,3,3))

# suport vector machine (binary). Multiclass classification is not implemented unitl now. When it works I&#39;ll update this tutorial
svm_model &lt;- iris_bin_training %&gt;%
  ml_linear_svc(Species ~ .)</code></pre>
</div>
<div id="predicting" class="section level2">
<h2>Predicting</h2>
<p>Remember, only thing you have to do is use <code>pred &lt;- sdf_predict(test_data, your_model)</code>, let’s check three examples.</p>
<pre class="r"><code>pred_lm &lt;- sdf_predict(mtcars_test, lm_model) # linear regression - regression
pred_gbt_bin &lt;- sdf_predict(iris_bin_test, gbt_model_bin) # gradient tree boosting - binary
pred_nb &lt;- sdf_predict(iris_test, nb_model)   # naive bayes - multiclass</code></pre>
<p>For the others models just use the same way…try it and have fun ;)</p>
</div>
<div id="evaluating" class="section level2">
<h2>Evaluating</h2>
<p>In this part, I have to give you some details. For example, let’s take a look in <code>ml_binary_classification_eval()</code>.</p>
<pre class="r"><code>ml_binary_classification_eval(x, label_col = &quot;label&quot;,
  prediction_col = &quot;prediction&quot;, metric_name = &quot;areaUnderROC&quot;)</code></pre>
<p>Note that you have to pass the parameters <code>label_col</code> and <code>prediction_col</code>. You don’t need to “worry” about it because sparklyr create these columns with same default name when you use <code>sdf_predict()</code>, look:</p>
<pre class="r"><code>dplyr::glimpse(pred_nb)
## Observations: ??
## Variables: 14
## $ Sepal_Length           &lt;dbl&gt; 4.3, 4.4, 4.4, 4.7, 4.8, 4.9, 4.9, 5.0,...
## $ Sepal_Width            &lt;dbl&gt; 3.0, 2.9, 3.2, 3.2, 3.1, 2.5, 3.1, 3.0,...
## $ Petal_Length           &lt;dbl&gt; 1.1, 1.4, 1.3, 1.3, 1.6, 4.5, 1.5, 1.6,...
## $ Petal_Width            &lt;dbl&gt; 0.1, 0.2, 0.2, 0.2, 0.2, 1.7, 0.2, 0.2,...
## $ Species                &lt;chr&gt; &quot;setosa&quot;, &quot;setosa&quot;, &quot;setosa&quot;, &quot;setosa&quot;,...
## $ features               &lt;list&gt; [&lt;4.3, 3.0, 1.1, 0.1&gt;, &lt;4.4, 2.9, 1.4,...
## $ label                  &lt;dbl&gt; 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, ...
## $ rawPrediction          &lt;list&gt; [&lt;-11.881783, -11.384971, -9.929243&gt;, ...
## $ probability            &lt;list&gt; [&lt;0.1031988, 0.1696044, 0.7271968&gt;, &lt;0...
## $ prediction             &lt;dbl&gt; 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, ...
## $ predicted_label        &lt;chr&gt; &quot;setosa&quot;, &quot;setosa&quot;, &quot;setosa&quot;, &quot;setosa&quot;,...
## $ probability_virginica  &lt;dbl&gt; 0.10319876, 0.13955037, 0.11483333, 0.1...
## $ probability_versicolor &lt;dbl&gt; 0.1696044, 0.2175782, 0.1869394, 0.1807...
## $ probability_setosa     &lt;dbl&gt; 0.727196821, 0.642871385, 0.698227263, ...</code></pre>
<p>Did you see? <code>pred_nb</code> contains the columns named <code>label</code> and <code>prediction</code>. That is why you just need to pass <code>pred_nb</code> to your evaluator. Easy, isn’t it? Take a look in these examples:</p>
<pre class="r"><code># gradient tree boosting
ml_binary_classification_evaluator(pred_gbt_bin)
## [1] 0.825

# naive bayes
ml_multiclass_classification_evaluator(pred_nb)
## [1] 0.9184959</code></pre>
<p>But, why am I using worry in quotation marks? It’s because some models don’t create the column <code>label</code>, for example, <code>ml_linear_regression()</code>. Let’s check <code>pred_lm</code> out!</p>
<pre class="r"><code>dplyr::glimpse(pred_lm)
## Observations: ??
## Variables: 12
## $ mpg        &lt;dbl&gt; 10.4, 10.4, 14.3, 15.8, 18.1, 19.7, 21.4, 22.8
## $ cyl        &lt;dbl&gt; 8, 8, 8, 8, 6, 6, 4, 4
## $ disp       &lt;dbl&gt; 460.0, 472.0, 360.0, 351.0, 225.0, 145.0, 121.0, 140.8
## $ hp         &lt;dbl&gt; 215, 205, 245, 264, 105, 175, 109, 95
## $ drat       &lt;dbl&gt; 3.00, 2.93, 3.21, 4.22, 2.76, 3.62, 4.11, 3.92
## $ wt         &lt;dbl&gt; 5.424, 5.250, 3.570, 3.170, 3.460, 2.770, 2.780, 3.150
## $ qsec       &lt;dbl&gt; 17.82, 17.98, 15.84, 14.50, 20.22, 15.50, 18.60, 22.90
## $ vs         &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 1, 1
## $ am         &lt;dbl&gt; 0, 0, 0, 1, 0, 1, 1, 0
## $ gear       &lt;dbl&gt; 3, 3, 3, 5, 3, 5, 4, 4
## $ carb       &lt;dbl&gt; 4, 4, 4, 4, 1, 6, 2, 2
## $ prediction &lt;dbl&gt; 14.63299, 15.72502, 13.12466, 24.98213, 21.58216, 1...</code></pre>
<p>OMG!!! What am I supposed to do? Easy, just pass <code>label_col = &quot;your_output&quot;</code> as parameter, in this case, <code>mpg</code></p>
<pre class="r"><code>ml_regression_evaluator(pred_lm, label_col = &quot;mpg&quot;)
## [1] 5.362564</code></pre>
</div>
<div id="thats-all-folks" class="section level2">
<h2>That’s all folks</h2>
<p>Liked it? You can share this tutorial using the buttons below. If you want to contribute with my website you can fork me on <a href="https://github.com/samuelmacedo83/my_webpage">github</a>. If you still have any doubts feel free to contact at <code>samuelmacedo@recife.ifpe.edu.br</code>.</p>
<p>See ya!</p>
</div>
</div>
